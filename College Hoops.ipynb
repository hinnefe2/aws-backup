{
 "metadata": {
  "name": "",
  "signature": "sha256:8dff2dae7b785a8b6cadb367c3d8c644a63cda0a30632379b5d9771050483cd3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import datetime\n",
      "import re\n",
      "from bs4 import BeautifulSoup\n",
      "from IPython.display import display, clear_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "This is what the html from espn.com looks like, with everything but the parts we care about removed\n",
      "\n",
      "</html>\n",
      "<div class=\"mod-content\">\n",
      "                        <div class=\"team visitor\">\n",
      "                            <div class=\"team-capsule\">\n",
      "                                <p class=\"team-name\" id=\n",
      "                                \"400591251-aNameOffset\"><span id=\n",
      "                                \"400591251-aTeamName\"><a href=\n",
      "                                \"http://espn.go.com/mens-college-basketball/team/_/id/171/columbia-lions\"\n",
      "                                title=\"Columbia\">Columbia</a></span></p>\n",
      "\n",
      "                                <p class=\"record\" id=\"400591251-aRecord\">\n",
      "                                (11-10, 3-4 Ivy)</p>\n",
      "                            </div>\n",
      "\n",
      "                            <ul class=\"score\" id=\"400591251-aScores\" style=\n",
      "                            \"display:block\">\n",
      "                                <li id=\"400591251-als2\">31</li>\n",
      "\n",
      "                                <li id=\"400591251-als3\">37</li>\n",
      "\n",
      "                                <li id=\"400591251-als4\">&nbsp;</li>\n",
      "\n",
      "                                <li class=\"final\" id=\n",
      "                                \"400591251-awayHeaderScore\">68</li>\n",
      "                            </ul>\n",
      "                        </div>\n",
      "\n",
      "                        <div class=\"team home\">\n",
      "                            <div class=\"team-capsule\">\n",
      "                                <p class=\"team-name\" id=\n",
      "                                \"400591251-hNameOffset\"><span id=\n",
      "                                \"400591251-hTeamName\"><a href=\n",
      "                                \"http://espn.go.com/mens-college-basketball/team/_/id/108/harvard-crimson\"\n",
      "                                title=\"Harvard\">Harvard</a></span></p>\n",
      "\n",
      "                                <p class=\"record\" id=\"400591251-hRecord\">(16-5,\n",
      "                                6-1 Ivy)</p>\n",
      "                            </div>\n",
      "\n",
      "                            <ul class=\"score\" id=\"400591251-hScores\" style=\n",
      "                            \"display:block\">\n",
      "                                <li id=\"400591251-hls2\">48</li>\n",
      "\n",
      "                                <li id=\"400591251-hls3\">24</li>\n",
      "\n",
      "                                <li id=\"400591251-hls4\">&nbsp;</li>\n",
      "\n",
      "                                <li class=\"final\" id=\n",
      "                                \"400591251-homeHeaderScore\">72</li>\n",
      "                            </ul>\n",
      "                        </div>\n",
      "\n",
      "</div>\n",
      "<html>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function to parse the html from espn.com using the BeautifulSoup library\n",
      "def parse_page(soup):\n",
      "    results = []\n",
      "    \n",
      "    # find all the divs with class=mod-content\n",
      "    mod_content_list = soup.find_all(\"div\", class_=\"mod-content\")\n",
      "    \n",
      "    # if there are no games that day return empty list\n",
      "    if len(mod_content_list)==7: # there are 7 non-game mod_content divs in each page\n",
      "        return results\n",
      "\n",
      "    # first 3 and last 4 aren't game results, iterate over the rest\n",
      "    for mod_content in mod_content_list[3:-4]:\n",
      "        # get away team info\n",
      "        try:\n",
      "            away_capsule = mod_content.find(\"div\", class_=\"team visitor\").find(\"div\", class_=\"team-capsule\")\n",
      "            away_name = away_capsule.find(\"a\").string\n",
      "            away_record = away_capsule.find(\"p\", class_=\"record\").string.replace(',',';') #replace the comma in the record w a semicolon since were saving as .csv\n",
      "            # if len(away_record)==1: away_record = 'NA' # the record is a single character string ' ' for non-DI schools\n",
      "        except:\n",
      "            away_name = 'Non D-I School'\n",
      "            away_record = 'NA'\n",
      "            \n",
      "        team_visitor = mod_content.find(\"div\", class_=\"team visitor\")\n",
      "        (away_half1, away_half2, dummy, away_total) = [li.string for li in team_visitor.find(\"ul\", class_=\"score\").find_all(\"li\")]\n",
      "        \n",
      "        # get home team info\n",
      "        try:\n",
      "            home_capsule = mod_content.find(\"div\", class_=\"team home\").find(\"div\", class_=\"team-capsule\")\n",
      "            home_name = home_capsule.find(\"a\").string\n",
      "            home_record = home_capsule.find(\"p\", class_=\"record\").string.replace(',',';') #replace the comma in the record w a semicolon since were saving as .csv\n",
      "            #if len(home_record)==1: home_record = 'NA' # the record is a single character string ' ' for non-DI schools\n",
      "        except:\n",
      "            home_name = 'Non D-I School'\n",
      "            home_record = 'NA'\n",
      "          \n",
      "        team_home = mod_content.find(\"div\", class_=\"team home\")\n",
      "        (home_half1, home_half2, dummy, home_total) = [li.string for li in team_home.find(\"ul\", class_=\"score\").find_all(\"li\")]\n",
      "          \n",
      "        # package this row's data as a list, store that list in the results array\n",
      "        results.append( [away_name, away_record, away_half1, away_half2, away_total, home_name, home_record, home_half1, home_half2, home_total])\n",
      "        \n",
      "    return results\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# url for espn men's basketball results\n",
      "# date variable must be in yyyymmdd format\n",
      "base_url = \"http://scores.espn.go.com/ncb/scoreboard?date=%s&confId=%s\"\n",
      "# value for 'confId' variable in base_url, 50 = all conferences\n",
      "conf_str = \"50\"\n",
      "\n",
      "# number of days of the season to scrape\n",
      "numdays=10\n",
      "# college season started Nov. 14\n",
      "start_date = datetime.date(2014,11,14)\n",
      "# list of dates starting at (start_date) at going for (numdays)\n",
      "date_list = [start_date + datetime.timedelta(days=x) for x in range(0, numdays)]\n",
      "\n",
      "# iterate over the list of dates\n",
      "for d in date_list:\n",
      "    # generate a string in the format yyyymmdd like the ESPN page wants\n",
      "    date_str= d.strftime('%Y%m%d')\n",
      "    \n",
      "    # keep track of what date we're currently scraping\n",
      "    clear_output(wait=True)\n",
      "    print(\"Fetching data from %s\" % d.strftime('%Y-%m-%d'))\n",
      "    \n",
      "    # open up the outputfile\n",
      "    with open('college_hoops.csv', 'a') as outfile:\n",
      "        # get the raw html from espn.com, pass it to the BeautifulSoup html parser\n",
      "        response = urllib.request.urlopen(base_url % (date_str, conf_str))\n",
      "        html = response.read()\n",
      "        soup = BeautifulSoup(html)\n",
      "        \n",
      "        # parse the html with the parse_page function written above\n",
      "        results = parse_page(soup)\n",
      "        \n",
      "        # write the results to the output file\n",
      "        for row in results:\n",
      "            row.insert(0,d.strftime('%Y-%m-%d')) # add the date to the beginning of the row\n",
      "            outfile.write(\", \".join(row))\n",
      "            outfile.write(\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching data from 2014-11-23\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}